@article{sardinha2024ai,
  title={AI-generated vs human-authored texts: A multidimensional comparison},
  author={Sardinha, Tony Berber},
  journal={Applied Corpus Linguistics},
  volume={4},
  number={1},
  pages={100083},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{dandekar2017comparative,
  title={Comparative evaluation of synthetic data generation methods},
  author={Dandekar, Ashish and Zen, Remmy AM and Bressan, St{\'e}phane},
  booktitle={Proceedings of ACM Conference (Deep Learning Security Workshop)},
  year={2017}
}
@article{zhang2024systematic,
  title={A Systematic Survey of Text Summarization: From Statistical Methods to Large Language Models},
  author={Zhang, Haopeng and Yu, Philip S and Zhang, Jiawei},
  journal={arXiv preprint arXiv:2406.11289},
  year={2024}
}
@article{li2023synthetic,
  title={Synthetic data generation with large language models for text classification: Potential and limitations},
  author={Li, Zhuoyan and Zhu, Hangxiao and Lu, Zhuoran and Yin, Ming},
  journal={arXiv preprint arXiv:2310.07849},
  year={2023}
}
@article{lu2023machine,
  title={Machine learning for synthetic data generation: a review},
  author={Lu, Yingzhou and Shen, Minjie and Wang, Huazheng and Wang, Xiao and van Rechem, Capucine and Wei, Wenqi},
  journal={arXiv preprint arXiv:2302.04062},
  year={2023}
}
@inproceedings{lee2024exploring,
  title={Exploring the Potential of Synthetic Data to Replace Real Data},
  author={Lee, Hyungtae and Zhang, Yan and Kwon, Heesung and Bhattacharyya, Shuvra S},
  booktitle={2024 IEEE International Conference on Image Processing (ICIP)},
  pages={1005--1011},
  year={2024},
  organization={IEEE}
}
@ARTICLE{9006873,
  author={Wu, Bin and Liu, Le and Yang, Yanqing and Zheng, Kangfeng and Wang, Xiujuan},
  journal={IEEE Access}, 
  title={Using Improved Conditional Generative Adversarial Networks to Detect Social Bots on Twitter}, 
  year={2020},
  volume={8},
  number={},
  pages={36664-36680},
  keywords={Feature extraction;Machine learning;Twitter;Classification algorithms;Generative adversarial networks;Clustering algorithms;Social bot detection;conditional generative adversarial networks;data augmentation;supervised classification;imbalanced data},
  doi={10.1109/ACCESS.2020.2975630}
}
@misc{li2023syntheticdatagenerationlarge,
      title={Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations}, 
      author={Zhuoyan Li and Hangxiao Zhu and Zhuoran Lu and Ming Yin},
      year={2023},
      eprint={2310.07849},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2310.07849}, 
}
@inproceedings{10.1145/3548785.3548793,
author = {Endres, Markus and Mannarapotta Venugopal, Asha and Tran, Tung Son},
title = {Synthetic Data Generation: A Comparative Study},
year = {2022},
isbn = {9781450397094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3548785.3548793},
doi = {10.1145/3548785.3548793},
abstract = {Generating synthetic data similar to realistic data is a crucial task in data augmentation and data production. Due to the preservation of authentic data distribution, synthetic data provide concealment of sensitive information and therefore enable Big Data acquisition for model training without facing privacy challenges. Nevertheless, the obstacles arise starting with acquiring real-world open-source data to effectively synthesizing new samples as genuine as possible. In this paper, a comparative study is conducted by considering the efficacy of different generative models like Generative Adversarial Networks (GAN), Variational Autoencoder (VAE), Synthetic Minority Oversampling Technique (SMOTE), Data Synthesizer (DS), Synthetic Data Vault with Gaussian Copula (SDV-G), Conditional Generative Adversarial Networks (SDV-GAN), and SynthPop Non-Parametric (SP-NP) approach to synthesize data with regard to various datasets. We used the pairwise correlation and Synthetic Data (SD) metrics as utility measures respectively between real data and generated data for evaluation. Accordingly, this paper investigates the effects of various data generation models, and the processing time of every model is included as one of the evaluation metrics.},
booktitle = {Proceedings of the 26th International Database Engineered Applications Symposium},
pages = {94â€“102},
numpages = {9},
keywords = {Synthetic Data, Neural Networks, Generative Models},
location = {Budapest, Hungary},
series = {IDEAS '22}
}
@article{basyal2023text,
  title={Text summarization using large language models: a comparative study of MPT-7B-instruct, Falcon-7b-instruct, and OpenAI Chat-GPT models},
  author={Basyal, Lochan and Sanghvi, Mihir},
  journal={arXiv preprint arXiv:2310.10449},
  year={2023}
}
@article{lee2020biobert,
  title={BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
  author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  journal={Bioinformatics},
  volume={36},
  number={4},
  pages={1234--1240},
  year={2020},
  publisher={Oxford University Press}
}
@article{ji2020bert,
  title={Bert-based ranking for biomedical entity normalization},
  author={Ji, Zongcheng and Wei, Qiang and Xu, Hua},
  journal={AMIA Summits on Translational Science Proceedings},
  volume={2020},
  pages={269},
  year={2020},
  publisher={American Medical Informatics Association}
}
@inproceedings{liu2021clinical,
  title={Clinical trial information extraction with BERT},
  author={Liu, Xiong and Hersch, Greg L and Khalil, Iya and Devarakonda, Murthy},
  booktitle={2021 IEEE 9th International Conference on Healthcare Informatics (ICHI)},
  pages={505--506},
  year={2021},
  organization={IEEE}
}
@article{durango2023named,
  title={Named entity recognition in electronic health records: A methodological review},
  author={Durango, Mar{\'\i}a C and Torres-Silva, Ever A and Orozco-Duque, Andr{\'e}s},
  journal={Healthcare Informatics Research},
  volume={29},
  number={4},
  pages={286},
  year={2023},
  publisher={Korean Society of Medical Informatics}
}
@article{campos2012biomedical,
  title={Biomedical named entity recognition: a survey of machine-learning tools},
  author={Campos, David and Matos, S{\'e}rgio and Oliveira, Jos{\'e} Lu{\'\i}s},
  journal={Theory and applications for advanced text mining},
  volume={11},
  pages={175--195},
  year={2012},
  publisher={InTech Rijeka, Croatia}
}
@inproceedings{adhikari2020nlp,
  title={Nlp based machine learning approaches for text summarization},
  author={Adhikari, Surabhi and others},
  booktitle={2020 Fourth International Conference on Computing Methodologies and Communication (ICCMC)},
  pages={535--538},
  year={2020},
  organization={IEEE}
}
@inproceedings{merchant2018nlp,
  title={Nlp based latent semantic analysis for legal text summarization},
  author={Merchant, Kaiz and Pande, Yash},
  booktitle={2018 international conference on advances in computing, communications and informatics (ICACCI)},
  pages={1803--1807},
  year={2018},
  organization={IEEE}
}
@inproceedings{chen2021news,
  title={News text summarization method based on bart-textrank model},
  author={Chen, Yisong and Song, Qing},
  booktitle={2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)},
  pages={2005--2010},
  year={2021},
  organization={IEEE}
}
@inproceedings{asmitha2024summarizing,
  title={Summarizing News: Unleashing the Power of BART, GPT-2, T5, and Pegasus Models in Text Summarization},
  author={Asmitha, M and Kavitha, CR and Radha, D},
  booktitle={2023 4th International Conference on Intelligent Technologies (CONIT)},
  pages={1--6},
  year={2024},
  organization={IEEE}
}
@inproceedings{myla2024enhanced,
  title={Enhanced Text Summarization through Hybrid Integration of RoBERTa, T5, and Pegasus Models},
  author={Myla, Sameera Datta and Saini, Ravinder and Kapoor, Nitika},
  booktitle={2024 International Conference on Advances in Modern Age Technologies for Health and Engineering Science (AMATHE)},
  pages={1--8},
  year={2024},
  organization={IEEE}
}
@article{dharrao2024summarizing,
  title={Summarizing Business News: Evaluating BART, T5, and PEGASUS for Effective Information Extraction.},
  author={Dharrao, Deepak and Mishra, Manasvi and Kazi, Aqsa and Pangavhane, Madhuri and Pise, Priya and Bongale, Anupkumar M},
  journal={Revue d'Intelligence Artificielle},
  volume={38},
  number={3},
  year={2024}
}
@article{borah2022comparative,
  title={Comparative analysis of T5 model for abstractive text summarization on different datasets},
  author={Borah, Mrinmoi and Dadure, Pankaj and Pakray, Partha and others},
  year={2022}
}
@article{chen4979696enhancing,
  title={Enhancing Data Quality in Medical Concept Normalization Through Large Language Models},
  author={Chen, Haihua and Li, Ruochi and Ding, Junhua and Cleveland, Ana},
  journal={Available at SSRN 4979696}
}
@article{galeano2022machine,
  title={Machine learning prediction of side effects for drugs in clinical trials},
  author={Galeano, Diego and Paccanaro, Alberto},
  journal={Cell Reports Methods},
  volume={2},
  number={12},
  year={2022},
  publisher={Elsevier}
}
@article{lewis2019bart,
  title={Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, M},
  journal={arXiv preprint arXiv:1910.13461},
  year={2019}
}
